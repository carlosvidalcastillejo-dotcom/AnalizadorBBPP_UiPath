"""
Esc√°ner de proyectos UiPath
Recorre recursivamente todos los XAML de un proyecto
"""

from pathlib import Path
from typing import List, Dict, Optional
import json

from src.xaml_parser import XamlParser
from src.analyzer import BBPPAnalyzer, Finding
from src.config import DEFAULT_CONFIG


class ProjectScanner:
    """Esc√°ner de proyectos UiPath"""
    
    def __init__(self, project_path: Path, config: Dict = None, active_sets: List[str] = None):
        """
        Inicializar esc√°ner
        
        Args:
            project_path: Ruta al proyecto UiPath
            config: Configuraci√≥n de an√°lisis
            active_sets: Lista de conjuntos de reglas activos (ej: ['UiPath', 'NTTData'])
        """
        self.project_path = Path(project_path)
        self.config = config or DEFAULT_CONFIG
        self.active_sets = active_sets if active_sets is not None else ['UiPath', 'NTTData']
        self.xaml_files = []
        self.parsed_files = []
        self.all_findings = []
        self.project_info = {}
        
    def scan(self, progress_callback=None) -> Dict:
        """
        Escanear el proyecto completo
        
        Args:
            progress_callback: Funci√≥n para reportar progreso (file_path, percentage)
            
        Returns:
            Diccionario con resultados del an√°lisis
        """
        import time
        self._start_time = time.time()  # Para calcular tiempo de ejecuci√≥n
        
        # 1. Detectar tipo de proyecto
        self.project_info = self._detect_project_info()
        
        # 2. Encontrar todos los XAML
        self.xaml_files = self._find_xaml_files()
        
        if not self.xaml_files:
            return {
                'success': False,
                'error': 'No se encontraron archivos XAML en el proyecto',
                'project_path': str(self.project_path)
            }
        
        # 3. Analizar cada XAML
        # Cargar reglas espec√≠ficas si se definieron active_sets
        rules = None
        if self.active_sets:
            from src.rules_manager import get_rules_manager
            rm = get_rules_manager()
            rules = rm.get_active_rules(self.active_sets)
            
        analyzer = BBPPAnalyzer(self.config, rules=rules, active_sets=self.active_sets)
        total_files = len(self.xaml_files)
        
        for idx, xaml_file in enumerate(self.xaml_files):
            # Reportar progreso
            if progress_callback:
                percentage = ((idx + 1) / total_files) * 100
                progress_callback(xaml_file.name, percentage)
            
            # Parsear XAML
            parser = XamlParser(xaml_file)
            parsed_data = parser.parse()
            
            if 'error' not in parsed_data:
                self.parsed_files.append(parsed_data)
                
                # Analizar BBPP
                findings = analyzer.analyze(parsed_data)
                self.all_findings.extend(findings)
        
        # 3.5 Analizar dependencias y proyecto global
        project_findings = analyzer.analyze_project(self.project_info)
        self.all_findings.extend(project_findings)
        
        # 4. Calcular estad√≠sticas
        stats = self._calculate_statistics()
        
        # 5. Calcular score
        score = self._calculate_score(stats)
        
        # Preparar resultado
        result = {
            'success': True,
            'project_path': str(self.project_path),
            'project_info': self.project_info,
            'total_files': total_files,
            'analyzed_files': len(self.parsed_files),
            'statistics': stats,
            'score': score,
            'findings': [f.to_dict() for f in self.all_findings],
            'parsed_files': self.parsed_files,
        }
        
        # 6. Guardar en base de datos de m√©tricas (auto-save)
        try:
            from src.database.metrics_db import get_metrics_db
            
            start_time = getattr(self, '_start_time', time.time())
            execution_time = time.time() - start_time
            
            # A√±adir tiempo de ejecuci√≥n al resultado
            result['execution_time'] = execution_time
            
            # Guardar en BD
            db = get_metrics_db()
            analysis_id = db.save_analysis(result)
            db.close()
            
            # Opcional: a√±adir ID al resultado
            result['analysis_id'] = analysis_id
            
            # AUTO-GENERACI√ìN DE REPORTES (NUEVO)
            from src.config import load_user_config
            config = load_user_config()
            auto_generate = config.get('output', {}).get('auto_generate_reports', True)
            
            if auto_generate:
                html_path = None
                excel_path = None
                
                # Generar HTML si est√° habilitado
                if config.get('output', {}).get('generate_html', True):
                    try:
                        from src.report_generator import HTMLReportGenerator
                        html_gen = HTMLReportGenerator(result)
                        html_path = html_gen.generate()
                        print(f"‚úÖ Reporte HTML generado autom√°ticamente: {html_path}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Error al generar HTML autom√°ticamente: {e}")
                
                # Generar Excel si est√° habilitado
                if config.get('output', {}).get('generate_excel', False):
                    try:
                        from src.excel_report_generator import ExcelReportGenerator, OPENPYXL_AVAILABLE
                        if OPENPYXL_AVAILABLE:
                            excel_gen = ExcelReportGenerator(
                                result,
                                include_charts=config.get('output', {}).get('include_charts', True)
                            )
                            excel_path = excel_gen.generate()
                            print(f"‚úÖ Reporte Excel generado autom√°ticamente: {excel_path}")
                        else:
                            print("‚ö†Ô∏è  openpyxl no disponible - Excel no generado")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Error al generar Excel autom√°ticamente: {e}")
                
                # Guardar rutas en la base de datos
                if html_path or excel_path:
                    try:
                        from src.report_utils import update_analysis_report_paths
                        update_analysis_report_paths(analysis_id, html_path, excel_path)
                        print(f"‚úÖ Rutas de reportes guardadas en BD (ID: {analysis_id})")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Error al guardar rutas en BD: {e}")
            
        except Exception as e:
            # No fallar si no se puede guardar m√©tricas o generar reportes
            print(f"‚ö†Ô∏è  No se pudo guardar en base de datos de m√©tricas o generar reportes: {e}")
        
        return result
    
    def _detect_project_info(self) -> Dict:
        """Detectar informaci√≥n del proyecto"""
        info = {
            'name': self.project_path.name,
            'path': str(self.project_path),
            'type': 'Unknown',
            'has_framework': False,
            'has_main': False,
            'dependencies': [],
            'studio_version': 'Unknown',
        }
        
        # Buscar project.json
        project_json = self.project_path / 'project.json'
        if project_json.exists():
            try:
                with open(project_json, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    info['name'] = data.get('name', info['name'])
                    info['description'] = data.get('description', '')
                    
                    # Extraer versi√≥n de Studio
                    info['studio_version'] = data.get('studioVersion', 'Unknown')
                    
                    # Extraer dependencias (solo informaci√≥n, sin juzgar)
                    dependencies = data.get('dependencies', {})
                    for package_name, version in dependencies.items():
                        # Limpiar versi√≥n: UiPath usa formato "[2.12.3]"
                        clean_version = version.strip('[]') if isinstance(version, str) else version
                        package_info = {
                            'name': package_name,
                            'version': clean_version
                        }
                        info['dependencies'].append(package_info)
                    
                    # Extraer informaci√≥n adicional
                    info['project_version'] = data.get('projectVersion', 'Unknown')
                    info['entry_points'] = data.get('entryPoints', [])
                    
            except Exception as e:
                info['error_reading_project_json'] = str(e)
        
        # Detectar REFramework
        framework_indicators = [
            'Framework/InitAllSettings.xaml',
            'Framework/GetTransactionData.xaml',
            'Framework/Process.xaml',
        ]
        
        if all((self.project_path / indicator).exists() for indicator in framework_indicators):
            info['type'] = 'REFramework'
            info['has_framework'] = True
        
        # Buscar Main.xaml
        main_xaml = self.project_path / 'Main.xaml'
        if main_xaml.exists():
            info['has_main'] = True
        
        return info
    
    def _find_xaml_files(self) -> List[Path]:
        """Encontrar todos los archivos XAML en el proyecto"""
        xaml_files = []
        
        # Buscar recursivamente
        for xaml_file in self.project_path.rglob('*.xaml'):
            # Ignorar carpetas espec√≠ficas si es necesario
            if '.local' not in str(xaml_file) and '.git' not in str(xaml_file):
                xaml_files.append(xaml_file)
        
        return sorted(xaml_files)
    
    def _calculate_statistics(self) -> Dict:
        """Calcular estad√≠sticas del an√°lisis"""
        stats = {
            'total_findings': len(self.all_findings),
            'errors': 0,
            'warnings': 0,
            'infos': 0,
            'by_category': {},
            'by_severity': {},
            'total_activities': 0,
            'total_variables': 0,
            'total_arguments': 0,
            'total_try_catch': 0,
            'total_logs': 0,
            'files_with_commented_code': 0,
            'total_commented_lines': 0,
        }
        
        # Contar por severidad
        for finding in self.all_findings:
            severity = finding.severity
            category = finding.category
            
            if severity == 'error':
                stats['errors'] += 1
            elif severity == 'warning':
                stats['warnings'] += 1
            elif severity == 'info':
                stats['infos'] += 1
            
            # Por categor√≠a
            stats['by_category'][category] = stats['by_category'].get(category, 0) + 1
            stats['by_severity'][severity] = stats['by_severity'].get(severity, 0) + 1
        
        # Estad√≠sticas de los archivos parseados
        for parsed_file in self.parsed_files:
            stats['total_activities'] += len(parsed_file.get('activities', []))
            stats['total_variables'] += len(parsed_file.get('variables', []))
            stats['total_arguments'] += len(parsed_file.get('arguments', []))
            stats['total_try_catch'] += len(parsed_file.get('try_catch_blocks', []))
            stats['total_logs'] += len(parsed_file.get('log_messages', []))
            
            commented = parsed_file.get('commented_code', {})
            if commented.get('commented_lines', 0) > 0:
                stats['files_with_commented_code'] += 1
                stats['total_commented_lines'] += commented.get('commented_lines', 0)
        
        return stats
    
    def _calculate_score(self, stats: Dict) -> Dict:
        """
        Calcular score del proyecto (0-100)
        
        Args:
            stats: Estad√≠sticas del an√°lisis
            
        Returns:
            Diccionario con score y detalles
        """
        # Puntuaci√≥n base
        base_score = 100
        
        # Pesos de severidad (desde config)
        error_weight = self.config.get('scoring', {}).get('error_weight', -10)
        warning_weight = self.config.get('scoring', {}).get('warning_weight', -3)
        info_weight = self.config.get('scoring', {}).get('info_weight', -0.5)
        
        # Calcular penalizaciones
        errors_penalty = stats['errors'] * abs(error_weight)
        warnings_penalty = stats['warnings'] * abs(warning_weight)
        infos_penalty = stats['infos'] * abs(info_weight)
        
        total_penalty = errors_penalty + warnings_penalty + infos_penalty
        
        # Ajuste por tama√±o del proyecto (evitar que proyectos grandes tengan score 0)
        # Factor de escala: Penalizaci√≥n por actividad
        total_activities = max(1, stats.get('total_activities', 1))
        penalty_per_activity = total_penalty / total_activities
        
        # Factor de sensibilidad: 
        # Si SCALING_FACTOR = 20, significa que 5 puntos de penalizaci√≥n por actividad = Score 0
        # (ej: 1 error cada 2 actividades)
        SCALING_FACTOR = 25 
        
        adjusted_penalty = penalty_per_activity * SCALING_FACTOR
        
        # Score final (m√≠nimo 0, m√°ximo 100)
        # Si el proyecto es muy peque√±o (< 10 actividades), usamos la penalizaci√≥n directa amortiguada
        if total_activities < 10:
            final_score = max(0, base_score - (total_penalty * 0.5))
        else:
            final_score = max(0, base_score - adjusted_penalty)
        
        # Determinar calificaci√≥n
        if final_score >= 90:
            grade = 'A - Excelente'
            color = 'green'
        elif final_score >= 80:
            grade = 'B - Muy Bien'
            color = 'lightgreen'
        elif final_score >= 70:
            grade = 'C - Bien'
            color = 'yellow'
        elif final_score >= 60:
            grade = 'D - Aceptable'
            color = 'orange'
        else:
            grade = 'F - Necesita Mejoras'
            color = 'red'
        
        return {
            'score': round(final_score, 2),
            'grade': grade,
            'color': color,
            'penalties': {
                'errors': errors_penalty,
                'warnings': warnings_penalty,
                'infos': infos_penalty,
                'total': total_penalty,
            }
        }
    
    def get_summary(self) -> str:
        """Obtener resumen textual del an√°lisis"""
        if not self.parsed_files:
            return "No se ha realizado ning√∫n an√°lisis todav√≠a."
        
        stats = self._calculate_statistics()
        score = self._calculate_score(stats)
        
        summary = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë           RESUMEN DEL AN√ÅLISIS DE BUENAS PR√ÅCTICAS            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìÅ PROYECTO: {self.project_info.get('name', 'Unknown')}
üìÇ Tipo: {self.project_info.get('type', 'Unknown')}
üîß UiPath Studio: {self.project_info.get('studio_version', 'Unknown')}

üìä SCORE GLOBAL: {score['score']}/100 - {score['grade']}

üìà ESTAD√çSTICAS:
   ‚Ä¢ Archivos analizados: {len(self.parsed_files)}
   ‚Ä¢ Total actividades: {stats['total_activities']}
   ‚Ä¢ Total variables: {stats['total_variables']}
   ‚Ä¢ Total argumentos: {stats['total_arguments']}

‚ö†Ô∏è  HALLAZGOS:
   ‚Ä¢ ‚ùå Errors: {stats['errors']}
   ‚Ä¢ ‚ö†Ô∏è  Warnings: {stats['warnings']}
   ‚Ä¢ ‚ÑπÔ∏è  Info: {stats['infos']}
   ‚Ä¢ Total: {stats['total_findings']}

üìù POR CATEGOR√çA:
"""
        
        for category, count in stats['by_category'].items():
            summary += f"   ‚Ä¢ {category}: {count}\n"
        
        if stats['files_with_commented_code'] > 0:
            # Calcular porcentaje promedio
            total_commented = stats['total_commented_lines']
            total_lines = sum(f.get('total_lines', 0) for f in self.parsed_files)
            avg_percentage = (total_commented / total_lines * 100) if total_lines > 0 else 0
            
            summary += f"\nüí¨ C√ìDIGO COMENTADO:\n"
            summary += f"   ‚Ä¢ Encontrado {avg_percentage:.1f}% promedio de c√≥digo comentado en:\n"
            
            # Listar archivos con porcentajes individuales
            for parsed_file in self.parsed_files:
                commented_lines = parsed_file.get('commented_lines', 0)
                if commented_lines > 0:
                    file_total_lines = parsed_file.get('total_lines', 0)
                    file_percentage = (commented_lines / file_total_lines * 100) if file_total_lines > 0 else 0
                    file_name = Path(parsed_file.get('file_path', '')).stem  # Sin extensi√≥n
                    summary += f"     - {file_name} ({file_percentage:.1f}%)\n"
            
            summary += f"   ‚Ä¢ Total l√≠neas comentadas: {total_commented}\n"
        
        # Informaci√≥n de dependencias
        dependencies = self.project_info.get('dependencies', [])
        if dependencies:
            summary += f"\nüì¶ DEPENDENCIAS ({len(dependencies)} paquetes):\n"
            
            # Mostrar primeros 10 paquetes
            for pkg in dependencies[:10]:
                name = pkg.get('name', 'Unknown')
                # Soporte para formato antiguo y nuevo
                version = pkg.get('installed_version') or pkg.get('version') or 'No instalada'
                status = pkg.get('status_label', '')
                
                if status:
                    summary += f"   ‚Ä¢ {name}: {version} ({status})\n"
                else:
                    summary += f"   ‚Ä¢ {name}: {version}\n"
            
            if len(dependencies) > 10:
                summary += f"   ... y {len(dependencies) - 10} paquetes m√°s\n"
        
        return summary
